{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import torch\n",
    "from torch import Tensor, linalg\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from IPython.display import Latex\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the Data Matrix and the Label vector\n",
    "Read data into torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.,  0.,  0.,  ..., 18., 18., 18.])\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "# Specify the top-level folder\n",
    "top_folder = 'data'\n",
    "\n",
    "# Initialize an empty list to store flattened arrays\n",
    "flattened_arrays = []\n",
    "labels = torch.zeros(9120)\n",
    "example_cnt,example_label = 0,0\n",
    "\n",
    "# Recursively iterate over each file in each folder\n",
    "for root, dirs, files in os.walk(top_folder):\n",
    "    \n",
    "    for file in files:\n",
    "        # Check if the file is a text file\n",
    "        if file.endswith('.txt'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            \n",
    "            # Initialize an empty list to store lines\n",
    "            lines = []\n",
    "            \n",
    "            # Open the file in read mode\n",
    "            with open(file_path, 'r') as file:\n",
    "                # Read each line in the file\n",
    "                for line in file:\n",
    "                    # Remove newline character and split the line by comma\n",
    "                    values = line.strip().split(',')\n",
    "                    # Convert values to integers and append to the list of lines\n",
    "                    lines.append([float(value) for value in values])\n",
    "            \n",
    "            # Flatten the list of lines into a 1D array\n",
    "            flattened_array = torch.tensor(lines).view(-1)\n",
    "            labels[example_cnt] = example_label\n",
    "            \n",
    "            # Append the flattened array to the list of flattened arrays\n",
    "            flattened_arrays.append(flattened_array)\n",
    "            example_cnt += 1\n",
    "            \n",
    "            if example_cnt%480 == 0:\n",
    "                example_label += 1\n",
    "\n",
    "# Convert the list of flattened arrays to a 2D tensor\n",
    "all_data_1 = torch.stack(flattened_arrays)\n",
    "\n",
    "all_data_2 = torch.zeros((all_data_1.shape[0],45))\n",
    "\n",
    "for i in range(all_data_2.shape[1]):\n",
    "    all_data_2[:,i] = all_data_1[:,i*125:i*125+125].mean(1)\n",
    "\n",
    "# Print the resulting 2D tensor\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the Dataset into Training and Test sets\n",
    "Split dataset into training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_indices = [i for i in range(len(all_data_1)) if (i % 60) < 48]\n",
    "test_indices = [i for i in range(len(all_data_1)) if (i % 60) >= 48]\n",
    "\n",
    "training_data_1 = all_data_1[training_indices]\n",
    "test_data_1 = all_data_1[test_indices]\n",
    "\n",
    "training_data_2 = all_data_2[training_indices]\n",
    "test_data_2 = all_data_2[test_indices]\n",
    "\n",
    "training_labels = labels[training_indices]\n",
    "test_labels = labels[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduced data using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=100)\n",
    "pca.fit(training_data_1)\n",
    "training_data_1_reduced = Tensor(pca.transform(training_data_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Using K-Means and Normalized Cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means(points: Tensor, k: int, relative_error: float = 1e-6, max_iterations: int = 1000):\n",
    "    n = len(points)\n",
    "    means = points[torch.randperm(n)[:k]]\n",
    "\n",
    "    error = 1\n",
    "    iterations = 0\n",
    "    while error > relative_error and iterations < max_iterations:\n",
    "        iterations += 1\n",
    "        distances = torch.cdist(points, means)\n",
    "        closest_means = torch.argmin(distances, dim=1)\n",
    "\n",
    "        new_means = torch.zeros_like(means)\n",
    "        for i in range(k):\n",
    "            new_means[i] = points[closest_means == i].mean(dim=0)\n",
    "\n",
    "        error = torch.norm(means - new_means) / torch.norm(new_means)\n",
    "\n",
    "        means = new_means\n",
    "\n",
    "    return means, closest_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means_2(points:Tensor,k):\n",
    "    \n",
    "    '''\n",
    "        points: dataset\n",
    "        k: number of clusters\n",
    "    '''\n",
    "    plen = len(points[0]) if points.ndim > 1 else 1\n",
    "    means = points[torch.randperm(len(points))[:k]]\n",
    "    itr = 0\n",
    "    while True:\n",
    "        itr+=1\n",
    "        classes = [[] for _ in range(k)]\n",
    "        \n",
    "        for j,point in enumerate(points):\n",
    "            min_distance = torch.inf\n",
    "            nearest_mean = None\n",
    "        \n",
    "            for i in range (len(means)):\n",
    "                distance = torch.linalg.norm(point - means[i])\n",
    "                if distance < min_distance:\n",
    "                    min_distance = distance\n",
    "                    nearest_mean = i\n",
    "            \n",
    "            classes[nearest_mean].append((j+1,point))\n",
    "           \n",
    "        new_means = torch.tensor([[0.0 for _ in range(plen)] for _ in range(k)]) \n",
    "        for i,c in enumerate(classes):\n",
    "            n = float(len(c))\n",
    "            new_mean = torch.tensor([0.0 for _ in range(plen)])\n",
    "            for j,point in c:\n",
    "                new_mean+=point\n",
    "            new_mean = new_mean/n\n",
    "            new_means[i] = new_mean\n",
    "        \n",
    "        if(torch.equal(new_means,means)):\n",
    "            return classes\n",
    "        \n",
    "        means = new_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### solution1:Taking the mean of each column in each segment for each data point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### solution2:Flattening all the features together for each data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = [8, 13, 19, 28,38]\n",
    "ks = [13]\n",
    "classes = [[] for i in range(19)]\n",
    "for k in ks:\n",
    "    means, mylabels = k_means(training_data_1_reduced,k)\n",
    "    # for i,lbl in enumerate(mylabels):\n",
    "    #     classes[lbl].append(i)\n",
    "    \n",
    "    # classes = k_means_2(training_data_1_reduced,k)\n",
    "    \n",
    "    # for i in range(len(classes)):\n",
    "    #     classes[i] = [classes[i][j][0] - 1 for j in range(len(classes[i]))]\n",
    "               \n",
    "    # mylabels = np.zeros(19)\n",
    "    # for i,c in  enumerate(classes):\n",
    "    #     for idx in c:\n",
    "    #         mylabels[idx-1] = i\n",
    "        \n",
    "    #accuracy = torch.sum(labels == mylabels)/len(labels)\n",
    "    \n",
    "    #print(f'accuracy for k = {k} is {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_entropy(clusters,labels,sizes):\n",
    "    '''\n",
    "        labels: true labels for each point\n",
    "        sizes : size of each true label(no. of points in each true label)\n",
    "    '''\n",
    "    conditional_entropy_t = 0\n",
    "    num_of_samples = len(labels)\n",
    "    for cluster in clusters:\n",
    "        if(len(cluster) == 0): continue\n",
    "        count = torch.zeros(len(sizes))\n",
    "        for sample in cluster:\n",
    "            count[torch.tensor(labels[sample], dtype=torch.long)]+=1\n",
    "        htc_i = 0\n",
    "        for cnt in count:    \n",
    "            div = cnt/len(cluster)\n",
    "            htc_i += (-cnt/len(cluster) * (math.log2(div) if div else 0))\n",
    "\n",
    "        conditional_entropy_t += (len(cluster)/num_of_samples)*htc_i\n",
    "        \n",
    "    return conditional_entropy_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0956)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MARWAN\\AppData\\Local\\Temp\\ipykernel_30064\\1683548033.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  count[torch.tensor(labels[sample], dtype=torch.long)]+=1\n"
     ]
    }
   ],
   "source": [
    "sizes = torch.full((19,), 384)\n",
    "\n",
    "val = conditional_entropy(classes,training_labels,sizes)\n",
    "\n",
    "print(val)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from torch import Tensor, linalg\n",
    "import numpy as np\n",
    "from IPython.display import Latex\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "image_count_per_person = 10\n",
    "person_count = 40\n",
    "images = [Image.open(f\"../data/s{j + 1}/{i + 1}.pgm\") for j in range(person_count) for i in range(image_count_per_person)]\n",
    "\n",
    "#A 3d array\n",
    "all_data = np.array(images)\n",
    "\n",
    "#A 2d array (n*d) => (400*10304)\n",
    "all_data.resize((image_count_per_person * person_count, images[0].width * images[0].height))\n",
    "\n",
    "all_data = Tensor(all_data)\n",
    "\n",
    "labels = torch.tensor([i for i in range(person_count) for _ in range(image_count_per_person)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the Dataset into Training and Test sets\n",
    "Split dataset into training and test data taking the even indexed rows for testing and the odd indexed rows for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200])\n"
     ]
    }
   ],
   "source": [
    "odd_indices = [i for i in range(len(all_data)) if i % 2 == 1]\n",
    "even_indices = [i for i in range(len(all_data)) if i % 2 == 0]\n",
    "\n",
    "training_data = all_data[odd_indices]\n",
    "test_data = all_data[even_indices]\n",
    "\n",
    "training_labels = labels[odd_indices]\n",
    "test_labels = labels[even_indices]\n",
    "\n",
    "print(training_labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification using LDA\n",
    "## Original LDA Algorithm\n",
    "Running Time: $O(d^3)$ to calculate the eigen values and eigen vectors of $\\Sigma_{d \\times d}$ matrix\\\n",
    "\\\n",
    "![lda](../res/lda.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDA(D , y):\n",
    "    n_features = len(D[0])\n",
    "    n_classes = len(torch.unique(y))\n",
    "    \n",
    "    overall_mean = torch.mean(D ,dim=0)\n",
    "\n",
    "    # between-class scatter\n",
    "    Sb = torch.zeros((n_features , n_features))\n",
    "\n",
    "    # within-class scatter\n",
    "    S = torch.zeros((n_features , n_features))\n",
    "\n",
    "    for i in range (n_classes):\n",
    "        Kth_class = D[y == i]\n",
    "        cur_mean = torch.mean(Kth_class , dim=0)\n",
    "       \n",
    "        # calculate between class scatter matrix\n",
    "        centered_kth_mean = (cur_mean - overall_mean).unsqueeze(1)\n",
    "        Sb += (Kth_class.shape[0] * Tensor.matmul(centered_kth_mean,centered_kth_mean.T))\n",
    "\n",
    "        # calculate within class scatter matrix\n",
    "        centered_kth_class = Kth_class - cur_mean\n",
    "        S += Tensor.matmul(centered_kth_class.T,centered_kth_class)\n",
    "\n",
    "\n",
    "    #compute matrix (S^-1*B) \n",
    "    A = linalg.pinv(S) @ Sb\n",
    "    \n",
    "    #Compute the eignValues and eignVectors\n",
    "    eigenvalues, eigenvectors = linalg.eig(A)\n",
    "    eigenvalues, eigenvectors =eigenvalues.real, eigenvectors.real\n",
    "    \n",
    "    #Sort the eignValues and eignVectors\n",
    "    idxs = torch.argsort(eigenvalues,descending=True)\n",
    "    eigenvectors = eigenvectors[:,idxs]\n",
    "\n",
    "    return eigenvectors[:,:n_classes-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(test_data: Tensor, training_data: Tensor, k: int):\n",
    "    distance_matrix = torch.cdist(test_data, training_data)\n",
    "    indices = torch.argsort(distance_matrix, dim=1)\n",
    "    return indices[:, :k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection_matrix = LDA(training_data,training_labels)   #(10304 * 39)\n",
    "print(\"projection_matrix Dimension : \",projection_matrix.shape)\n",
    "\n",
    "projected_training_matrix = training_data @ projection_matrix\n",
    "projected_test_matrix = test_data @ projection_matrix\n",
    "\n",
    "print(\"Done Projection\")\n",
    "print(\"projected_training_matrix Dimension : \",projected_training_matrix.shape)\n",
    "k = 1\n",
    "\n",
    "result_labels = training_labels[knn(projected_test_matrix,projected_training_matrix, k)].mode(keepdim=True)[0]\n",
    "print(\"Accuracy: \",1 - torch.count_nonzero(result_labels - test_labels[:, None]) / len(result_labels))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
